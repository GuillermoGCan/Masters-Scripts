install.packages("mlogit")
read.csv("train.csv", stringsAsFactors = FALSE)
train <- read.csv("train.csv", stringsAsFactors = FALSE)
View(train)
library(mlogit)
?mlogit
Tr <- mlogit.data(train, shape="wide") #shape = wide se refiere
Tr <- mlogit.data(train, shape="wide", choice = "choice", varying = 4:11,
sep = "", alt.levels = c(1,2), id="id")
Tr <- mlogit.data(train, shape="wide", choice = "choice", varying = 4:11,
sep = "", id="id")
View(Tr)
head(Tr)
View(train)
#conversión de unidades: minutos a horas y guilders a euros
Tr$price <- Tr$price/100*2.20371
Tr$time <- Tr$time/60
head(Tr)
#Logit
ml <- mlogit(choice ~ price + time + change + comfort | -1, Tr)
summary(ml)
coef(ml)
coef(ml)[-1]
coef(ml)[1]
coef(ml)[-1]/coef(ml)[1]
class(coef(ml))
class(c(1,2,3))
fish <- read.csv("fishing.csv")
View(fish)
View(fish)
View(fish)
# Convertir al formato de mlogit:
d <- mlogit.data(fish, varying = c(2:9), shape="wide", choice = "mode")
head(d)
# Sin constantes específicas:
simple_model <- mlogit(mode ~ price + catch | 0, d)
summary(simple_model)
# Comparemos nuestro modelo contra la predicción simple
t <- data.frame(table(fish$mode))
View(t)
sum(t$Freq)
colnames(t) <- c("mode", "Obs")
View(t)
t$pct_observed <- t$Obs/nrow(fish)
View(t)
t2 <- data.frame(apply(fitted(simple_model, outcome=FALSE), 2, mean))
colnames(t2) <- "pct_predicted"
t2$mode <- row.names(t2)
View(t2)
View(t)
fitted(simple_model, outcome=FALSE)
View(simple_model)
View(d)
View(fish)
const_esp <- mlogit(mode ~ price + catch, d, reflevel = "beach")
summary(const_esp)
t3 <- data.frame(apply(fitted(simple_model, outcome=FALSE), 2, mean))
colnames(t3) <- "pct_predicted"
t3$mode <- row.names(t3)
t
t3
t3 <- data.frame(apply(fitted(const_esp, outcome=FALSE), 2, mean))
colnames(t3) <- "pct_predicted"
t3$mode <- row.names(t3)
t
t3
caract_ingreso <- mlogit(mode ~ price + catch | income, d, reflevel = "boat")
summary(caract_ingreso)
## Cuando empiezo a comparar modelos utilizo el log likelihood para elegir el mejor
test <- lrtest(const_esp, caract_ingreso)
print(test)
test <- lrtest(simple_model,const_esp, caract_ingreso)
print(test)
test <- lrtest(const_esp, caract_ingreso)
print(test)
catch_var <- mlogit(mode ~ price | income | catch, d, reflevel = "boat")
summary(catch_var)
test <- lrtest(caract_ingreso, catch_var)
print(test)
fittedv <- fitted(catch_var, outcome = FALSE)
View(fittedv)
# Ver demanda agregada
apply(fittedv, 2, mean)
X <- model.matrix(catch_var)
View(X)
# Model matrix te saca del modelo todas las variables que se utilizaron
alt <- index(d)$alt
chid <- index(d)$chid
eXb <- as.numeric(exp(X %*% coef(catch_var)))
SeXb <- tapply(eXb, chid, sum)
P <- eXb/SeXb[chid]
# ordenar la matriz de probabilidades
P <- matrix(P,ncol = 4, byrow=TRUE)
apply(P, 2, mean)
P <- matrix(P,ncol = 4, byrow=TRUE)
head(P)
head(fittedv)
apply(P, 2, mean)
P <- eXb/SeXb[chid]
head(P)
# ordenar la matriz de probabilidades
P <- matrix(P, ncol = 4, byrow=TRUE)
head(P)
head(fittedv)
apply(P, 2, mean)
# Estima elasticidades de demanda a cambios en el precio de pier:
newX <- function(d,X,catch_var, constante){
t1 <- replicate(nrow(X), 1)
for(i in 1:length(t1)){
if (i %% 4 == 0){
t1[i] <- constante
}
}
X[,4] <- X[,4]*t1
alt <- index(d)$alt
chid <- index(d)$chid
eXb <- as.numeric(exp(X %*% coef(catch_var)))
SeXb <- tapply(eXb, chid, sum)
P <- eXb/SeXb[chid]
P <- matrix(P, ncol = 4, byrow = TRUE)
head(P)
return(apply(P,2,mean))
}
X <- model.matrix(catch_var)
nexX(d,X,catch_var,1.20)
newX(d,X,catch_var,1.20)
library(readx1)
library(plyr)
library(dplyr)
library(stringr)
library(sqldf)
library(pscl)
library(readxl)
d <- read.csv("200524COVID19MEXICO.csv", stringsAsFactors = FALSE)
d2 <- d[d$RESULTADO==1,] #Filtro el resultado = 1, osea que salieron positivos a la prueba
dim(d2)
d2$DEFUNCION <- ifelse(d2$FECHA_DEF!="9999-99-99",1,0)
d2$INTUBADO2 <- ifelse(d2$INTUBADO == 1,1,0)
d2$CARDIOVASCULAR <- ifelse(d2$CARDIOVASCULAR == 1,1,0)
d2$NEUMONIA <- ifelse(d2$NEUMONIA == 1, 1, 0)
d2$HIPERTENSION <- ifelse(d2$HIPERTENSION == 1, 1, 0)
d2$DIABETES <- ifelse(d2$DIABETES == 1, 1, 0)
d2$ASMA <- ifelse(d2$ASMA == 1, 1, 0)
table(d2$INTUBADO2, d2$DEFUNCION)
# Generalized Linear Model (GLM)
fit <- glm(DEFUNCION ~ INTUBADO2, data = d2, family=binomial(logit))
summary(fit)
#La magnitud de los coeficientes no tiene una interpretación directa,
#se tienen que convertir a probabilidades.
pR2(fit)
# Estimador McFadden me da una especie de R2
logit2prob <- function(logit){
odds <- exp(logit)
prob <- odds/(1+odds)
return(prob)
}
# Log_deceso = intercept + b_intubado*clase(valor)
coef(fit)
intercept <- coef(fit)[1]
b_intubado <- coef(fit)[2]
x_intubado = 1
logit_deceso <- intercept + x_intubado*b_intubado
logit2prob(logit_deceso)
# Se puede sacar automáticamente con la función predict.
# Predice la probabilidad (response) de deceso cuando el paciente está intubado (INTUBADO2=1)
predict(fit,data.frame(INTUBADO2=1), type="response")
# Agregar más variables
fit2 <- glm(DEFUNCION ~ INTUBADO2 + ASMA + CARDIOVASCULAR + NEUMONIA + HIPERTENSION
+ DIABETES, data = d2, family=binomial(logit))
summary(fit2)
pR2(fit2) # a partir de 0.4 es bastante bueno
#Utilizar nuestro modelo como un elemento de predicción.
p <- predict(fit2, type="response")
summary(p)
plot(density(p))
# ¿Cómo fijar mi threshold a partir del cuál defino si hay o no hay defunciones?
p2 <- ifelse(p>0.5,1,0)
table(p2)
## AUC (Area Under the Curve) ROC (Receiver Operating Characteristic)
#install.packages("ROCR")
library(ROCR)
pr <- prediction(p,d2$DEFUNCION)
summary(pr)
slotNames(pr)
pr@cutoffs
pr@predictions
pr@labels
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
abline(a=0, b=1)
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc # va de 0 a 1. 0.5 no hay relación, cercano a 1 es mucha dependencia.
acc.perf = performance(pr, measure="acc")
plot(acc.perf)
ind = which.max(slot(acc.perf, "y.values")[[1]])
acc = slot(acc.perf, "y.values")[[1]][ind]
cutoff = slot(acc.perf, "x.values")[[1]][ind]
print(c(accuracy=acc, cutoff=cutoff))
# Doy mi threshold...
p2 <- ifelse(p>0.5443165,1,0)
table(p2)
sample(1:nrow(d2), nrow(d2)/2)
al_tr <- sample(1:nrow(d2), nrow(d2)/2)
train <- d2[al_tr,]
test <- d2[!al_tr,]
test <- d2[-al_tr,]
View(test)
View(test)
View(train)
test2 <- d2[!row.names(d2) %in% al_tr,]
test = test2
ifelse(test = test2, 1, 0)
test <- d2[!row.names(d2) %in% al_tr,]
remove(test2)
